# Summary
언젠간 알고가야 하는 가상 메모리 (페이징 기법)

# Concept
## 시작점 : 연속 메모리 할당의 문제점
* 외부 단편화
* 물리 메모리보다 큰 프로세스 실행 불가
### 가상 메모리
내가 실행하고자 하는 프로그램의 일부만 메모리에 적재해서, 실제 물리 메모리보다 큰 프로세스를 실행할 수 있게 하는 기술
### 가상 메모리 관리 기법
* 페이징 (주로 사용됨)
* 세그멘테이션
## 페이징이란?
외부 단편화 : 각기 '다른' 크기의 프로세스가 메모리에 연속적으로 할당되었기 때문   
프로세스 메모리들을 일정 크기의 블럭들로 구성한다면? 외부 단편화 발생 X
> 모든 프로세스를 <b>일정한 크기</b>로 자르고, 이를 <b>불연속적</b>으로 메모리에 할당하는 것   

* (프로세스의) 논리 주소 공간을 페이지라는 일정 단위로 자르고
* (메모리의) 물리 주소 공간을 프레임이라는 페이지와 동일한 일정 단위로 자른 뒤
* 페이지를 프레임에 할당하는 가상 메모리 관리 기법
### 페이징에서의 스와핑
* 페이지 인
* 페이지 아웃
> 프로세스 단위가 아닌 페이지 단위의 스왑 인 / 아웃   
> 프로세스를 실행하기 위해 모든 페이지가 적재될 필요가 없다.
## 페이지 테이블
### 불연속 적재의 문제
* 프로세스를 이루는 페이지가 어느 프레임에 적재되어 있는지 알기 어렵고
* 순차적으로 실행할 수 없으므로
* 다음 실행할 명령어의 위치를 찾기가 어려워짐
### 해결법 : 페이지 테이블
* 페이지 번호와 프레임 번호의 사상(매핑) 관계를 기록한 표
* 프로세스마다 페이지 테이블이 있다.
* 메모리에 불연속적으로 적재되어 있더라도 CPU 입장에서는 연속적으로 보임

| 페이지 번호 | 프레임 번호 |
|:---:|:---:|
|0|3|
|1|5|
|2|2|
### 내부 단편화
* 하나의 페이지 크기보다 작은 크기의 메모리를 적재하는 경우 빈 공간이 생김
### PTBR (Page Table Base Register)
* 프로세스마다 있는 페이지 테이블의 주소를 가리키는 레지스터
* 하지만 페이지 테이블이 메모리에 있다면? <b>접근 시간이 두배</b>
    * 페이지 테이블 참조에 한번
    * 페이지 참조에 한번
> 페이지 테이블이 메모리에 있는 것이 효율적이지 않을 수 있다.
### TLB (Translation Lookaside Buffer)
CPU 곁에서 페이지 테이블을 저장하는 캐시 메모리
* TLB 히트 : CPU가 접근하려는 메모리 주소가 TLB에 있는 경우 -> 메모리 1번 접근
* TLB 미스 : CPU가 접근하려는 메모리 주소가 TLB에 있는 경우 -> 메모리 2번 접근
### 페이징에서의 주소 변환
* 어떤 정보가 필요할까?
1. 어떤 페이지 / 어떤 프레임에 접근하고 싶은지 (Page Number)
2. 접근하려는 주소가 1번 위치에서 얼마나 떨어져 있는지 (Offset)
## 요구 페이징
* 처음부터 모든 페이지를 적재하지 않고 <b>요구되는 페이지만</b> 적재하는 기법
### 유효 비트
페이지 엔트리 (페이지 테이블의 행 정보) 중 하나로 해당 페이지가 메모리에 적재되어 있는지를 나타내는 비트 플래그   
> 이런 요구 페이징 시스템이 안정적으로 작동하려면?
* 페이지 교체
* 프레임 할당
## 페이지 교체 알고리즘
1. 요구 페이징 기법으로 적재하다보면 메모리가 가득참
2. 당장 실행에 필요한 페이지를 적재하기 위해선, 이미 적재된 페이지를 보조기억장치로 페이지 아웃 해야함
3. 어떤걸 보내야할까? 를 결정하는 알고리즘
### 무엇이 좋은 페이지 교체 알고리즘일까?
 * <b>페이지 폴트</b>가 적은 알고리즘
 * 그럼 페이지 폴트 횟수는 어떻게 알지?
 * 페이지 참조열을 통해서
    * CPU가 참조하는 페이지들 중 연속된 페이지를 생략한 배열
    * 2 2 2 3 5 5 5 3 3 7 -> 2 3 5 3 7
### FIFO 페이지 교체 알고리즘
* 가장 단순
* 메모리에 가장 먼저 올라온 페이줍터 내쫓는 방식
* 유효 : 프로그램 실행 초기에 잠깐 실행될 페이지
* 맹점 : 프로그램 실행 내내 사용되는 페이지
### FIFO 알고리즘 보완책 - 2차 기회 (Second Chance)
* 참조 비트가 1이면 참조 비트를 0으로 하고 가장 뒤로 보냄
* 가장 앞의 페이지가 참조 비트가 0이면 내보냄
### 최적 페이지 교체 알고리즘
* 앞으로의 사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘
* 가장 낮은 페이지 폴트율을 보장
* 하지만 실제 구현이 어려움 - 앞으로 오랫동안 사용되지 않을 페이지를 어떻게 알 수 있지?
* 다른 페이지 교체 알고리즘의 성능 평가를 위한 하한선으로 사용됨
### LRU (Least-Recently-Used) 페이지 교체 알고리즘
* 최적 페이지 교체 알고리즘 : 가장 오래 사용되지 **않을** 페이지 교체
* LRU 페이지 교체 알고리즘 : 가장 오래 사용되지 **않은** 페이지 교체
## 프레임 할당
페이지 폴트가 자주 발생하는 이유는 꼭 나쁜 페이지 교체 알고리즘때문은 아님   
**프로세스가 사용할 수 있는 프레임 자체가 적은 경우**도 있다.
### 스래싱 (Thrasing)
프로세스가 실행되는 시간보다 페이징에 더 많은 시간을 소요하여 성능이 저해되는 문제
* 동시 실행되는 프로세스의 수가 많다고 CPU 이용률이 높아지는 것은 아니다.   
* 너무 많아지면 스래싱으로 인해 CPU 이용률이 오히려 떨어짐
> 각 프로세스가 필요로하는 최소한의 프레임 수를 파악하고 적절히 할당해줘야 한다.
### 프레임 할당 방법
#### 균등 할당
* 가장 단순
* 모든 프로세스들에게 균등하게 프레임을 할당하는 방식
#### 비례 할당
* 프로세스의 크기에 비례하여 프레임 할당
* 하지만 프로세스의 크기와 메모리 사용량은 항상 비례하진 않는다.
#### 작업 집합 모델
* CPU가 특정 시간 동안 참조한 페이지 개수 만큼만 프레임을 할당   
* 2 1 1 2 3 4 5 5 5 5 6 6 7 7 8 1 1 2 4   
* 시간 간격 : 7   
#### 페이지 폴트 빈도
1. 페이지 폴트율이 너무 높으면 프레임 수를 늘린다.
2. 페이지 폴트율이 너무 낮으면 프레임 수를 줄인다.

# Wrap-up
연속 메모리 할당의 문제점을 해결하기 위해 가상 메모리 관리 기법이 나왔고, 그 중 페이징이 주로 사용된다. 페이징은 논리 주소와 물리 주소를 일정한 크기로 나눠서 매핑하는 방식으로, 프로세스의 일정 부분만 메모리에 올려서 사용하므로 연속 메모리 할당의 문제점을 해결할 수 있다. 하지만 내부 단편화의 문제가 존재하며, PTBR나 TLB를 사용하여 주소를 변환한다. 또한 페이징 기법을 효율적으로 사용하기 위해선, 페이지 교체 알고리즘과, 프레임 할당을 잘 해야한다.

# Reference
[[운영체제] TLB(Translation Lookaside Buffer)](https://blog.naver.com/kgr2626/222147205118)